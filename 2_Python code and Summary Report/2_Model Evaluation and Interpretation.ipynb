{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b73f6d",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "\n",
    "[**I. Descriptive Statistics**](#II.-Descriptive-Statistics)\n",
    "\n",
    "[**II. Model Validation**](#III.-Model-Validation)\n",
    "1. [LASSO Regression](#a.-LASSO-Regression)\n",
    "2. [Random Forest](#b.-Random-Forest)\n",
    "3. [Model Comparison](#c.-Comparison-of-the-2-Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47e6a7d",
   "metadata": {},
   "source": [
    "### I. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import required libraries and functions\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, validation_curve\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "### Display decimals to the nearest 100th, for legibility\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d092e8d",
   "metadata": {},
   "source": [
    "### II. Descriptive Statistics\n",
    "\n",
    "* **Print the summary statistics of the variables (without the outlier)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89257193",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_outlier = pd.read_csv('1_Dataset/[FINAL] SVI and SDOH 2016-2020 (Cleaned).csv').iloc[: , 1:]\n",
    "\n",
    "data_no_outlier.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41dfff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_stats(data, file_name):\n",
    "    \n",
    "    '''Create a descriptive summary of the main variables (*excluding* the additional indicators)'''\n",
    "    main_features = data.iloc[:, list(range(4, 20)) + [31]].copy()\n",
    "    main_summary = main_features.describe()\n",
    "    print('\\nDescriptive Statistics of the 16 Main Social Vulnerability Index:\\n')\n",
    "    display(main_summary)\n",
    "    \n",
    "    '''Create a descriptive summary of the *additional* variables (+ the target variable)'''\n",
    "    supplementary_features = data.iloc[:, list(range(20, 29)) + [31]].copy()\n",
    "    supplementary_summary = supplementary_features.describe()\n",
    "    print('\\nDescriptive Statistics of the Supplementary Variables:\\n')\n",
    "    display(supplementary_summary)\n",
    "    \n",
    "    '''Create a correlation matrix for only the main variables\n",
    "    Visualize the correlation matrix using a heatmap'''\n",
    "    correlation_matrix = main_features.corr()\n",
    "    plt.subplots(figsize = (17, 12))\n",
    "    sns.heatmap(correlation_matrix, annot = True, fmt = '.2g')\n",
    "    plt.title(\"\\nA Correlation Matrix of \\n16 Social Vulnerability Indicators and Climate-induced Casualty\",\n",
    "              fontsize = 16, fontweight = 'bold')\n",
    "    \n",
    "    '''Save and display the heatmap'''\n",
    "    plt.savefig(file_name, bbox_inches = 'tight')\n",
    "    print('\\nCorrelation Heatmap:\\n')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ff883",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats(data_no_outlier, r'Correlation Matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71de9b7f",
   "metadata": {},
   "source": [
    "### III. Model Validation\n",
    "\n",
    "* **Partition the dataset into training and validation set**\n",
    "* **Scale the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d0d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set the random state\n",
    "randomstate = 20\n",
    "\n",
    "### Create a target array \n",
    "y = data_no_outlier['CASUALTY_PER_100K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ea5802",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a feature matrix\n",
    "X = data_no_outlier.iloc[:, 4:-3] # the 16 main social vulnerability indicators + 9 supplementary measures\n",
    "X.sample(3, random_state = randomstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2450b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Partition the data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,\n",
    "                                                    random_state = randomstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d87c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standardize the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec10c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a function that calculates the mean cross-validation score for the given hyperparameter of a model\n",
    "def mean_cv_score(model, X):\n",
    "    cv_scores = cross_val_score(model, X, y_test, cv = 5, scoring = 'neg_mean_absolute_error')\n",
    "    mean_cv_scores = -np.mean(cv_scores)\n",
    "    print('Mean cross-validation score: %.3f' % mean_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a683d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a function that summarizes the performance of a model\n",
    "def Performance_MAE_MSE_RMSE(y_test, y_prediction):\n",
    "    MAE = mean_absolute_error(y_test, y_prediction)\n",
    "    MSE = mean_squared_error(y_test, y_prediction)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    print('Mean Absolute Error: %.3f' % MAE)\n",
    "    print('Mean Squared Error: %.3f' % MSE)\n",
    "    print('Root Mean Squared Error: %.3f' % RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b07ee",
   "metadata": {},
   "source": [
    "### a. LASSO Regression\n",
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6244bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit a lasso regression model\n",
    "lasso = Lasso(max_iter = 5000) # alpha = 1\n",
    "lasso.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e657d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the mean cross-validation score\n",
    "mean_cv_score(lasso, X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e13bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define a function that plots a validation curve\n",
    "\n",
    "def hyperparameter_tuning(model, features, parameter_name, parameter_range, optimal_value,\n",
    "                          x_axis, title, file_name, apply_log_scale = False):\n",
    "    \n",
    "    '''Calculate the validation scores for different values of the hyperparameter, using cross-validation'''\n",
    "    training_scores, validation_scores = validation_curve(model, features, y_train,\n",
    "                                                          param_name = parameter_name, param_range = parameter_range,\n",
    "                                                          # Use MAE, since it is less sensitive to outliers\n",
    "                                                          scoring = 'neg_mean_absolute_error', cv = 5)\n",
    "    \n",
    "    '''Calculate the mean and SD of the cross-validation scores for each value of the hyperparameter'''\n",
    "    training_scores_mean = -np.mean(training_scores, axis = 1)\n",
    "    validation_scores_mean = -np.mean(validation_scores, axis = 1)\n",
    "\n",
    "    '''Plot the validation curve'''\n",
    "    plt.figure(figsize = (12, 7))\n",
    "\n",
    "    plt.plot(parameter_range, training_scores_mean, label = 'Training error', marker = 'o')\n",
    "    plt.plot(parameter_range, validation_scores_mean, label = 'Validation error', marker = 'o')\n",
    "\n",
    "    plt.title(f'A Validation Curve for {title}\\n', fontsize = 18)\n",
    "    plt.xlabel(x_axis, fontsize = 16)\n",
    "    plt.ylabel('Mean Absolute Error', fontsize = 16)\n",
    "\n",
    "    '''Whether to convert the x-axis to log scale'''\n",
    "    if apply_log_scale:\n",
    "        plt.xscale('log')\n",
    "        plt.xticks(parameter_range, parameter_range) # Add every value within the hyperparameter range to the x-axis labels\n",
    "\n",
    "    # Add grid lines to the axes\n",
    "    plt.grid(axis = 'y', linestyle = '--') \n",
    "    plt.grid(axis = 'x', linestyle = '--') \n",
    "\n",
    "    # Add a vertical line at the optimal level of the hyperparameter\n",
    "    plt.axvline(x = optimal_value, linestyle = '--', color = 'r')\n",
    "\n",
    "    plt.legend() # Add a legend \n",
    "\n",
    "    plt.savefig(file_name)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f522ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the range of alphas, to test for validation\n",
    "alphas = [0.001, 0.01, 0.1, 1, 3, 5, 10, 100]\n",
    "\n",
    "### Create the validation curve\n",
    "hyperparameter_tuning(lasso, X_train_scaled, 'alpha', alphas, 3, 'Alpha (the penalty term)', 'Lasso Regression',\n",
    "                      r'2_Graphs and Plots/Validation Curve (LASSO).png', apply_log_scale = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce2cc4",
   "metadata": {},
   "source": [
    "#### Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1157464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit a lasso regression model, using alpha = 3\n",
    "\n",
    "lasso_alpha3 = Lasso(alpha = 3, max_iter = 5000)\n",
    "lasso_alpha3.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e29ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Examine how many coefficients shrink to 0 when alpha = 3 (N.B. alpha = 0 is equal to linear regression)\n",
    "\n",
    "# Create a function that returns the number of 0 coefficients, at a specified level of alpha\n",
    "def count_zero_coeffients(model):\n",
    "    coefficients = model.coef_ # store the regression coefficients generated by each model\n",
    "    is_coefficient_zero = coefficients == 0 # create an boolean array that indicates whether each coefficient is 0\n",
    "    return is_coefficient_zero.sum()\n",
    "\n",
    "count_zero_coeffients(lasso_alpha3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4d4e9",
   "metadata": {},
   "source": [
    "#### Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e0bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate the predicted Y values based on our *test* data\n",
    "y_predicted_lasso = lasso_alpha3.predict(X_test_scaled) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate model performance\n",
    "Performance_MAE_MSE_RMSE(y_test, y_predicted_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2752c377",
   "metadata": {},
   "source": [
    "#### Interpretation of feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc4b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store the LASSO regression coefficients\n",
    "LASSO_coefficients = pd.DataFrame({'Features': X.columns,\n",
    "                                   'LASSO Regression Coefficients': lasso_alpha3.coef_}) # coefficients of the LASSO model\n",
    "\n",
    "\n",
    "### Rearrange the coefficients in descending order, by their 'absolute' magnitudes:\n",
    "LASSO_coefficients = LASSO_coefficients.sort_values(by = ['LASSO Regression Coefficients'],\n",
    "                                                    key = abs,\n",
    "                                                    ascending = False).reset_index(drop = True)\n",
    "\n",
    "### Display the 7 variables that were ultimately retained\n",
    "LASSO_coefficients.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define a function that visualizes a summary of the relationship between the features and the target\n",
    "\n",
    "def draw_inference_about_features(df, column_name, length, width, custom_palette, title, x_axis, file_name):\n",
    "    \n",
    "    # Plot a bar chart\n",
    "    plt.figure(figsize = (length, width))\n",
    "    \n",
    "    # Set the background as gray\n",
    "    sns.set_style('ticks')\n",
    "    sns.set_context('talk')\n",
    "\n",
    "    sns.barplot(x = df[column_name], y = df['Features'],\n",
    "                orient = 'h', palette = custom_palette) # Set the colors of the bars\n",
    "\n",
    "    plt.title(f'A Summary of {title}', fontsize = 22)\n",
    "    plt.xlabel(x_axis, fontsize = 18)\n",
    "    plt.ylabel('Features', fontsize = 18)\n",
    "\n",
    "    plt.axvline(x = 0, linestyle = '--', color = 'black') # Add a dotted line where coefficient/importance = 0\n",
    "    plt.subplots_adjust(left = 0.15) # Adjust the left margins\n",
    "\n",
    "    plt.savefig(file_name)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot a bar chart showing the the magnitude and direction of the features\n",
    "\n",
    "# The Top 4 features = blue; feature with negative coefficient = green, remaining variables that were retained = yellow\n",
    "palette_LASSO = ['#1f77b4', '#1f77b4', '#1f77b4','#1f77b4', '#2ca02c','#ff7f0e', '#ff7f0e']\n",
    "\n",
    "draw_inference_about_features(LASSO_coefficients, 'LASSO Regression Coefficients', 35, 18, palette_LASSO,\n",
    "                              'Variable Selection (LASSO Regression)', 'Regression Coefficients',\n",
    "                              r'2_Graphs and Plots/Variable Selection (LASSO).png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5024a6",
   "metadata": {},
   "source": [
    "### b. Random Forest\n",
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit the random forest regression model\n",
    "random_forest = RandomForestRegressor(random_state = randomstate) # generate 100 trees\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e033db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the mean cross-validation score\n",
    "mean_cv_score(random_forest, X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea8e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the range of the tree depth, to test for validation\n",
    "tree_depth = np.arange(5, 20)\n",
    "\n",
    "### Plot the validation curve\n",
    "hyperparameter_tuning(random_forest, X_train, 'max_depth', tree_depth, 6, 'Maximum Tree Depth', 'Random Forest',\n",
    "                      r'Validation Curve (Random Forest).png', apply_log_scale = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee62acec",
   "metadata": {},
   "source": [
    "#### Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadc1b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit the random forest regression model with a maximum tree depth of 6\n",
    "random_forest_depth6 = RandomForestRegressor(random_state = randomstate, max_depth = 6)\n",
    "random_forest_depth6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a1f3ed",
   "metadata": {},
   "source": [
    "#### Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61150f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate the predicted Y values based on our *test* data\n",
    "y_predicted_random_forest = random_forest_depth6.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e622aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate model performance\n",
    "Performance_MAE_MSE_RMSE(y_test, y_predicted_random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217ea9c2",
   "metadata": {},
   "source": [
    "#### Interpretation of feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get feature importances\n",
    "importance = random_forest_depth6.feature_importances_\n",
    "\n",
    "### Create a dataframe that summarizes the feature importance of a random forest model\n",
    "Random_Forest_feature_importance = pd.DataFrame({'Features': X.columns,\n",
    "                                                 'Feature Importance (Random Forest)': importance})\n",
    "\n",
    "### Sort the features in order of their importance\n",
    "Random_Forest_feature_importance = Random_Forest_feature_importance.sort_values('Feature Importance (Random Forest)',\n",
    "                                                                                ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a879ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot a bar chart showing feature importance\n",
    "\n",
    "# Define the colors of the bars\n",
    "# The first 7 = blue; the following 10 features = green; remaining variables = yellow\n",
    "palette_random_forest = ['#1f77b4']*7 + ['#2ca02c']*10 + ['#ff7f0e']*(len(Random_Forest_feature_importance)-17)\n",
    "\n",
    "draw_inference_about_features(Random_Forest_feature_importance, 'Feature Importance (Random Forest)',\n",
    "                              32, 12, palette_random_forest,\n",
    "                              'Feature Importance (Random Forest)', 'Degree of Importance',\n",
    "                              r'Feature Importance (Random Forest).png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c018683",
   "metadata": {},
   "source": [
    "### c. Comparison of the 2 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a14666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of tuples containing the 1) predicted values of casualty and 2) title of the subplots\n",
    "models = [(y_predicted_lasso, 'LASSO Regression'),\n",
    "          (y_predicted_random_forest, 'Random Forest')]\n",
    "\n",
    "# Create a 1X2 subplot\n",
    "figs, axes = plt.subplots(nrows = 1, ncols = 2, figsize = (15, 8))\n",
    "\n",
    "# Add a global title\n",
    "figs.suptitle(\"Deviations from the Actual Number of Deaths and Injuries\", size = 20, weight = 'bold')\n",
    "figs.subplots_adjust(top = 0.93)\n",
    "\n",
    "# Plot each graph. Plot the actual values of casualy on the x-axis and predicted values on the y-axis\n",
    "for index, (y_predicted, title) in enumerate(models):\n",
    "    axis = axes[index]\n",
    "    axis.scatter(y_test, y_predicted, alpha = 0.5)\n",
    "    axis.plot([0, 850], [0, 850], linestyle = '--', color = 'red') # Draw a 45 degree line\n",
    "    axis.set_title(title)\n",
    "\n",
    "\n",
    "# Add a common y-axis label\n",
    "figs.add_subplot(111, frameon = False) # set to 111, so that it takes up the entire figure area\n",
    "plt.tick_params(labelcolor = 'none', top = False, bottom = False, left = False, right = False)\n",
    "plt.grid(False)\n",
    "plt.ylabel(\"Predicted Number of Casualty\", fontsize = 16, labelpad = 20)\n",
    "plt.xlabel(\"Actual Number of Casualty\", fontsize = 16, labelpad = 20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Actual vs. Predicted Values.png')\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
